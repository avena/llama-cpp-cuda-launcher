# Exemplo de configuração do servidor llama.cpp
# Copie este arquivo para .env e ajuste os valores conforme necessário

# URL do servidor llama.cpp (pode ser localhost ou IP como 192.168.50.1)
# Exemplos:
# LLAMA_SERVER_URL=http://localhost:8080
# LLAMA_SERVER_URL=http://192.168.50.1:8080
# LLAMA_SERVER_URL=http://10.0.0.5:8080
LLAMA_SERVER_URL=http://localhost:8080

# Configurações padrão (podem ser sobrescritas por modelo)
DEFAULT_MAX_TOKENS=2048
DEFAULT_TEMPERATURE=0.2